{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 2\n",
        "\n",
        "This assignment is due Friday, February 24 at 11:59pm Central Time. \n",
        "\n",
        "This assignment can be completed in **groups of two**. If you need to find a partner, please post in the pinned note on Piazza.\n",
        "\n",
        "Once you have formed your groups, the work you submit must belong only to your group members. Do not submit another team's work as your own, and do not allow another team to submit your work as their own. If you use resources you find online, you must cite those in your notebook.\n",
        "\n",
        "To submit this assignment, you should commit to your GitHub account:\n",
        "\n",
        "* your Net ID(s) in the netid file; one per line. Please do not put your name in your notebook; we will grade these anonymously.\n",
        "\n",
        "* a hw2.pdf printout of the completed notebook that shows all your answers.\n",
        "\n",
        "* your final hw2.ipynb notebook with outputs saved. If we run your notebook from scratch, it should produce an output identical to your PDF. You can edit your notebook however you want (on Colab, on your local machine, somewhere else); just upload the latest version of it to GitHub.\n",
        "\n",
        "Your GitHub account must submit contain all three of these, or you will lose points. We will not accept late work except in extreme settings."
      ],
      "metadata": {
        "id": "YXVZmY8ilriC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmmalHu_lq13",
        "outputId": "516b5fed-ac8c-46b9-fe1b-9c5f15353060"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'cs449w23' already exists and is not an empty directory.\n",
            "/content/cs449w23\n"
          ]
        }
      ],
      "source": [
        "# If using local runtime\n",
        "# base_dir = \"~/Documents\"\n",
        "# If using hosted runtime\n",
        "base_dir = \"/content\"\n",
        "\n",
        "# helper code from the course repository\n",
        "!cd $base_dir && git clone -q https://github.com/zachwooddoughty/cs449w23.git\n",
        "# install common pacakges used for deep learning\n",
        "!cd $base_dir/cs449w23/ && pip install -q -r requirements.txt\n",
        "\n",
        "# make sure we're in the right directory\n",
        "%cd $base_dir/cs449w23/\n",
        "!git pull -q origin main"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import datetime\n",
        "import math\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import IPython.display as ipd\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from pathlib import Path\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchsummary import summary\n",
        "from tqdm import tqdm\n",
        "\n",
        "from utils.gan import *"
      ],
      "metadata": {
        "id": "EVNH8KF1isWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GANs and Autoencoders\n",
        "\n",
        "This homework assignment builds off the GAN notebook and the Autoencoder notebook that we saw in class. You may copy any code from those notebooks into your code.\n",
        "\n",
        "For this assignment, you will combine the models introduced in those two notebooks to create a combined Autoencoder + GAN model. In particular, that will look something like this:\n",
        "\n",
        "![Diagram of model architecture](https://github.com/zachwooddoughty/cs449w23/raw/main/static/hw2_fig.png)\n",
        "\n",
        "We're giving you the defined models below and the skeleton of the training code, and you just need to define the optimizers and write the loss functions to allow these models to train together.\n",
        "\n",
        "If we write this in a functional representation, then the encoder $E(X)$ takes in a real image and outputs a $z$ vector, $G(z)$ takes in a $z$ vecotr and outputs an image $\\tilde X$, and $D(X)$ takes in an image and outputs a scalar probability.\n",
        "\n",
        "The autoencoder loss will be MSELoss comparing $X$ and $\\tilde X$ and the generator and discriminator will be otherwise the same as in a GAN. However, the tricky component is to get the model to train and reduce all three losses simultaneously."
      ],
      "metadata": {
        "id": "OM2yMtIH0OWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fix random seed\n",
        "torch.manual_seed(0)\n",
        "\n",
        "class MLPGenerator(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, \n",
        "                 number_of_hidden_layers: int, \n",
        "                 input_size: int, \n",
        "                 hidden_size: int, \n",
        "                 output_size: int,\n",
        "                 activation: torch.nn.Module):\n",
        "        \"\"\"Construct a simple MLP generator\"\"\"\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        assert number_of_hidden_layers >= 0, \"Generator number_of_hidden_layers must be at least 0\"\n",
        "        \n",
        "        dims_in = [input_size] + [hidden_size] * number_of_hidden_layers\n",
        "        dims_out = [hidden_size] * number_of_hidden_layers + [output_size] # final output should be the size of a true example\n",
        "        layers = []\n",
        "        for i in range(number_of_hidden_layers + 1):\n",
        "            layers.append(torch.nn.Linear(dims_in[i], dims_out[i]))\n",
        "            \n",
        "            if i < number_of_hidden_layers:\n",
        "                layers.append(activation)\n",
        "        \n",
        "        # apply Sigmoid after final layer to constrain generated images to [0, 1]\n",
        "        layers.append(torch.nn.Sigmoid())\n",
        "        \n",
        "        self.net = torch.nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x: torch.Tensor):\n",
        "        return self.net(x)\n",
        "\n",
        "class MLPDiscriminator(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, \n",
        "                 number_of_hidden_layers: int, \n",
        "                 input_size: int, \n",
        "                 hidden_size: int, \n",
        "                 activation: torch.nn.Module):\n",
        "        \"\"\"Construct a simple MLP discriminator\"\"\"\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        msg = \"Discriminator number_of_hidden_layers must be at least 0\"\n",
        "        assert number_of_hidden_layers >= 0, msg\n",
        "        \n",
        "        # final output dimension is scalar (probability image is real)\n",
        "        dims_in = [input_size] + [hidden_size] * number_of_hidden_layers\n",
        "        dims_out = [hidden_size] * number_of_hidden_layers + [1]\n",
        "        \n",
        "        layers = []\n",
        "        for i in range(number_of_hidden_layers + 1):\n",
        "            layers.append(torch.nn.Linear(dims_in[i], dims_out[i]))\n",
        "            \n",
        "            if i < number_of_hidden_layers:\n",
        "                layers.append(activation)\n",
        "        \n",
        "        # apply sigmoid after final layer to represent probability\n",
        "        layers.append(torch.nn.Sigmoid())\n",
        "        \n",
        "        self.net = torch.nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x: torch.Tensor):\n",
        "        return self.net(x)\n",
        "\n",
        "class MLPEncoder(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, \n",
        "                 number_of_hidden_layers: int, \n",
        "                 input_size: int, \n",
        "                 hidden_size: int, \n",
        "                 latent_size: int,\n",
        "                 activation: torch.nn.Module):\n",
        "        \"\"\"Construct a simple MLP encoder\"\"\"\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        assert number_of_hidden_layers >= 0, \"Encoder number_of_hidden_layers must be at least 0\"\n",
        "        \n",
        "        dims_in = [input_size] + [hidden_size] * number_of_hidden_layers\n",
        "        dims_out = [hidden_size] * number_of_hidden_layers + [latent_size]  # final output should be latent size\n",
        "        layers = []\n",
        "        for i in range(number_of_hidden_layers + 1):\n",
        "            layers.append(torch.nn.Linear(dims_in[i], dims_out[i]))\n",
        "            \n",
        "            if i < number_of_hidden_layers:\n",
        "                layers.append(activation)\n",
        "\n",
        "        self.net = torch.nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x: torch.Tensor):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self,\n",
        "                 number_of_hidden_layers: int, \n",
        "                 latent_size: int, \n",
        "                 hidden_size: int, \n",
        "                 output_size: int,\n",
        "                 activation_generator: torch.nn.Module = torch.nn.ReLU(),\n",
        "                 activation_discriminator: torch.nn.Module = torch.nn.LeakyReLU(0.2)\n",
        "                ):\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = MLPEncoder(\n",
        "            number_of_hidden_layers=number_of_hidden_layers, \n",
        "            input_size=output_size, \n",
        "            hidden_size=hidden_size, \n",
        "            latent_size=latent_size,\n",
        "            activation=activation_generator,\n",
        "        )\n",
        "                          \n",
        "        self.generator = MLPGenerator(\n",
        "            number_of_hidden_layers=number_of_hidden_layers, \n",
        "            input_size=latent_size, \n",
        "            hidden_size=hidden_size, \n",
        "            output_size=output_size,\n",
        "            activation=activation_generator\n",
        "        )\n",
        "        \n",
        "        self.discriminator = MLPDiscriminator(\n",
        "            number_of_hidden_layers=number_of_hidden_layers, \n",
        "            input_size=output_size, \n",
        "            hidden_size=hidden_size,\n",
        "            activation=activation_discriminator\n",
        "        )   "
      ],
      "metadata": {
        "id": "d_EPvBVEkuZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training hyperparameters\n",
        "image_size = 28\n",
        "batch_size = 64\n",
        "latent_size = 64\n",
        "hidden_size = 256\n",
        "number_of_hidden_layers = 2\n",
        "lr = 0.0002 #NS: changing from 0.00002 to 0.0002 based on piazza post discussion.\n",
        "epochs = 60\n",
        "\n",
        "# select device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# load MNIST dataset\n",
        "mnist = load_mnist(batch_size=batch_size)\n",
        "\n",
        "# initialize the model\n",
        "model = Model(\n",
        "    number_of_hidden_layers=number_of_hidden_layers, \n",
        "    latent_size=latent_size, \n",
        "    hidden_size=hidden_size, \n",
        "    output_size=image_size*image_size, \n",
        ").to(device)\n",
        "\n",
        "#NS EDIT: trying to use the optimizers from the class notebooks, one for each sub-part rather than just an optimizer for Model as a whole. can try the latter also as part of experimentation\n",
        "opt_discriminator = torch.optim.Adam(model.discriminator.parameters(), lr=lr)\n",
        "opt_generator = torch.optim.Adam(model.generator.parameters(), lr=lr)\n",
        "opt_encoder = torch.optim.Adam(model.encoder.parameters(), lr=lr)\n",
        "\n",
        "# discriminator loss function: binary cross-entropy loss\n",
        "discrim_loss_func = torch.nn.BCELoss()\n",
        "# autoencoder loss function: mean squared error between original and new image\n",
        "autoencoder_loss_func = torch.nn.MSELoss()\n",
        "\n",
        "# determine which labels will correspond to \"real\" and \"fake\" predictions from the discriminator\n",
        "label_real = 1.0\n",
        "label_fake = 0.0\n",
        "\n",
        "# select a fixed set of latent vectors z that we will use to visualize the GAN's generation quality each epoch\n",
        "fixed_latents = torch.randn((batch_size, latent_size)).to(device)"
      ],
      "metadata": {
        "id": "oYmhDlK_lWQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Coding (7 points)\n",
        "\n",
        "To get this code to run, you need to do two things.\n",
        "\n",
        "* First, instantiate the optimizer(s) you will use to update your model parameters. Remember that you will need to update parameters in `model.encoder`, `model.generator`, and `model.discriminator`. One decision you have to make is how many optimizers you want to use.\n",
        "\n",
        "* Write the training code below to compute the loss terms for each part of your model: `loss_discriminator`, `loss_generator`, and `loss_autoencoder`. As in the VAE notebook, you may want to consider weighting these losses differently.\n",
        "\n",
        "For full points, we must be able to run your notebook as is and reproduce (almost) exactly the same results."
      ],
      "metadata": {
        "id": "e5Q1xvO2Rwi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# log metrics\n",
        "loss_d = np.zeros(epochs)\n",
        "loss_g = np.zeros(epochs)\n",
        "loss_ae = np.zeros(epochs)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_epoch_size = 0\n",
        "\n",
        "    # Zero out grads at beginning of epoch\n",
        "    model.encoder.zero_grad()\n",
        "    model.discriminator.zero_grad()\n",
        "    model.generator.zero_grad()\n",
        "\n",
        "    for batch_idx, batch_data in enumerate(mnist):\n",
        "\n",
        "        x_real, y_real = batch_data\n",
        "        \n",
        "        # flatten input images and move to device\n",
        "        x_real = x_real.to(device)\n",
        "        n_batch = x_real.shape[0]\n",
        "        x_real = x_real.reshape(n_batch, -1)\n",
        "\n",
        "        # TODO: write your training code here to compute loss functions\n",
        "        #   for each model section\n",
        "\n",
        "        # NS: DISCRIMINATOR LOSS, d is trying to maximize objective log(D(x)) + log(1 - D(G(z))) #\n",
        "        model.discriminator.zero_grad() \n",
        "        #train on real inputs\n",
        "        y_real = torch.full((n_batch, 1), label_real, device=device)\n",
        "        preds_real = model.discriminator(x_real)\n",
        "        loss_real = discrim_loss_func(preds_real, y_real)\n",
        "        # train on a batch of synthesized inputs\n",
        "        z = torch.randn(n_batch, latent_size).to(device)\n",
        "        x_fake = model.generator(z)\n",
        "        y_fake = torch.full((n_batch, 1), label_fake, device=device)\n",
        "        preds_fake = model.discriminator(x_fake.detach())  # exclude generator from gradient computation\n",
        "        loss_fake = discrim_loss_func(preds_fake, y_fake)\n",
        "        # update discriminator weights\n",
        "        loss_discriminator = loss_real + loss_fake\n",
        "        loss_discriminator.backward()\n",
        "        opt_discriminator.step()\n",
        "\n",
        "        # NS: GENERATOR LOSS, d is minimizing log(1 - D(G(z))) #\n",
        "        model.generator.zero_grad()\n",
        "        # train on a batch of synthesized inputs\n",
        "        z = torch.randn(n_batch, latent_size).to(device)\n",
        "        x_fake = model.generator(z)\n",
        "        y_real = torch.full((n_batch, 1), label_real, device=device)\n",
        "        preds_fake = model.discriminator(x_fake)\n",
        "        loss_generator = discrim_loss_func(preds_fake, y_real)\n",
        "        loss_generator.backward()\n",
        "        # update generator weights\n",
        "        opt_generator.step()\n",
        "\n",
        "        # NS: AUTOENCODER #\n",
        "        model.encoder.zero_grad()\n",
        "        model.generator.zero_grad()\n",
        "        z = model.encoder(x_real)\n",
        "        x_fake = model.generator(z)\n",
        "        loss_autoencoder = autoencoder_loss_func(x_real, x_fake) #NS: autoencoder loss is MSE of x (input to encoder) compared to x* (output of generator)\n",
        "        loss_autoencoder.backward()\n",
        "        opt_encoder.step()\n",
        "        # update generator weights\n",
        "        opt_generator.step()\n",
        "        \n",
        "        \n",
        "        # log losses and scores\n",
        "        loss_d[epoch] += loss_discriminator.detach().item() * n_batch\n",
        "        loss_g[epoch] += loss_generator.detach().item() * n_batch\n",
        "        loss_ae[epoch] += loss_autoencoder.detach().item() * n_batch\n",
        "        total_epoch_size += n_batch\n",
        "\n",
        "      \n",
        "\n",
        "    loss_d[epoch] /= total_epoch_size\n",
        "    loss_g[epoch] /= total_epoch_size\n",
        "    loss_ae[epoch] /= total_epoch_size\n",
        "\n",
        "    if epoch == 0 or (epoch + 1) % max(1, epochs // 10) == 0:\n",
        "        total = loss_ae[epoch] + loss_g[epoch] + loss_d[epoch]\n",
        "        log = \"  \".join([\n",
        "            f\"Epoch: {epoch + 1:4d}\",\n",
        "            f\"AE Loss: {loss_ae[epoch]:8.3f}\",\n",
        "            f\"Gen Loss: {loss_g[epoch]:8.3f}\",\n",
        "            f\"Dis Loss: {loss_d[epoch]:8.3f}\",\n",
        "            f\"Total: {total:8.1f}\",\n",
        "        ])\n",
        "        print(log)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfyAKlI1l4UD",
        "outputId": "fe7d444d-ef1e-40d3-fd55-b1a9c9144aca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:    1  AE Loss:    0.121  Gen Loss:    3.147  Dis Loss:    0.540  Total:      3.8\n",
            "Epoch:    6  AE Loss:    0.070  Gen Loss:    6.369  Dis Loss:    0.122  Total:      6.6\n",
            "Epoch:   12  AE Loss:    0.053  Gen Loss:    3.573  Dis Loss:    0.452  Total:      4.1\n",
            "Epoch:   18  AE Loss:    0.037  Gen Loss:    1.669  Dis Loss:    0.873  Total:      2.6\n",
            "Epoch:   24  AE Loss:    0.029  Gen Loss:    1.291  Dis Loss:    1.063  Total:      2.4\n",
            "Epoch:   30  AE Loss:    0.024  Gen Loss:    1.195  Dis Loss:    1.074  Total:      2.3\n",
            "Epoch:   36  AE Loss:    0.021  Gen Loss:    1.169  Dis Loss:    1.085  Total:      2.3\n",
            "Epoch:   42  AE Loss:    0.019  Gen Loss:    1.192  Dis Loss:    1.061  Total:      2.3\n",
            "Epoch:   48  AE Loss:    0.017  Gen Loss:    1.219  Dis Loss:    1.040  Total:      2.3\n",
            "Epoch:   54  AE Loss:    0.017  Gen Loss:    1.268  Dis Loss:    1.016  Total:      2.3\n",
            "Epoch:   60  AE Loss:    0.016  Gen Loss:    1.311  Dis Loss:    1.004  Total:      2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you've trained your model, use the next two cells to sample some images from your generator."
      ],
      "metadata": {
        "id": "_81rHjXK2l1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nrows, ncols = (3, 3)\n",
        "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(3 * nrows, 3 * ncols))\n",
        "\n",
        "for row in range(nrows):\n",
        "    for col in range(ncols):\n",
        "        z = torch.randn(1, latent_size).to(device)\n",
        "        output = model.generator(z).reshape(image_size, image_size).detach().cpu()\n",
        "        axes[row, col].imshow(output.squeeze(), cmap='gray')\n",
        "        axes[row, col].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AScgZZX8szjq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "outputId": "d3a4c0de-cf81-40c7-aabb-ee842ca78486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x648 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch = next(iter(mnist))[0].to(device)\n",
        "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(8, 6))\n",
        "\n",
        "indices = np.argsort(np.random.rand(example_batch.shape[0]))[:3]\n",
        "\n",
        "for col, index in enumerate(indices):\n",
        "\n",
        "    example_image = example_batch[index].cpu()\n",
        "    axes[0, col].imshow(example_image.squeeze(), cmap='gray')\n",
        "    axes[0, col].set_title(\"Original Image\")\n",
        "    axes[0, col].axis('off')\n",
        "\n",
        "    image_input = example_image.flatten().unsqueeze(0).to(device)\n",
        "    recons_img = model.generator(model.encoder(image_input))\n",
        "    recons_img = recons_img.reshape(1, image_size, image_size).detach().cpu()\n",
        "    axes[1, col].imshow(recons_img.squeeze(), cmap='gray')\n",
        "    axes[1, col].set_title(\"Reconstructed Image\")\n",
        "    axes[1, col].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MRQy5q1btCk4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "abb21ecc-45d1-4fc1-ddbe-da8d92bacde1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Coding explanation (6 points)\n",
        "\n",
        "### 1. What did you do? (4 points)\n",
        "\n",
        "Describe your approach in your code above; what choices did you make and why?\n",
        "\n",
        "If you weren't able to get the model to train, you can still earn these points by describing what you tried and what didn't seem to work.\n",
        "\n",
        "Dataset: We use the MNIST dataset as ground truth data for our autoencoder and as real inputs to our discriminator. We do not make any preprocessing of the data.\n",
        "\n",
        "Hyperparameters: We have increased the learning rate originally provided by the homework because we observed that we could see better improvements on the training loss. We tried increasing the batch size to 256 and 128 but obtained worse results.\n",
        "\n",
        "Architecture: We kept the original hidden size and number of layers.\n",
        "\n",
        "Optimizers: We decided to use separate optimizers with the same configuration for each of the 3 components, as opposed to use only one for the whole model to prevent backpropagation from interfering with other models. This simplifies the training process as backpropagation happens in each model independently and enables us to be able to configure hyperparameters separately if needed.\n",
        "In the training loop, we use the autoencoder and gan notebooks form class as reference. To train the discriminator, we use BCE loss on predicted fake or real labels from real images and images the generator produced from a random latent space. To train the generator, we use BCE loss on the label produced by the discriminator on the images that it generates from a random latent space - note that this loss is the opposite of the discriminator loss for generated images. To train the autoencoder, we use real images to produce latent representations and then use those latent representations to generate images that resemble the originals, using MSE as our loss metric (note that the generator weights are also updated during this process). \n",
        "\n",
        "### 2. Discuss your results (2 points)\n",
        "\n",
        "If you were able to get your model to train, what did you notice about the trends in the three different loss values? How do your generated images in the previous cells look similar to or different from the images we saw in the GAN or Autoencoder notebooks?\n",
        "\n",
        "We see that the autoencoder loss decreases monotonically whereas the discriminator and the generator oscillate between increasing and decreasing their respective loss. The total loss tends to decrease. The generated digits look quite similar from the digits that we produced in the other notebooks, although the reconstructions produced by our autoencoder are not as close to the original as in the autoencoder notebook. This could be because our models are optimizing for more than one task at once. \n"
      ],
      "metadata": {
        "id": "QsPCyEjztSLl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conceptual questions (7 points)\n",
        "\n",
        "### 1. Mode collapse (2 points)\n",
        "\n",
        "Look back at the slides, notebook, and/or readings around mode collapse in GANs.\n",
        "* First, give a one or two sentence definition of what mode collapse is, in your own words.\n",
        "* Second, explain why mode collapse is *more* or *less* likely in the above model that incorporates an autoencoder into the GAN. Write at least two sentences.\n",
        "\n",
        "*Mode collapse occurs when the generator produces identical (or near-identical) output regardless of input. It generally happens when the discriminator gets too powerful (is easily able to distinguish between real and fake images) so the generator resorts to only generating a small set of identical samples that can consistently fool the discriminator rather than generating diverse images (which is what we want).*\n",
        "\n",
        "*Mode collapse is actually **less** likely to happen in a model with a GAN+encoder. The encoder, if trained well, learns latent representations in such a way that preserves the diversity of the training set (in a way that just sampling random noise, as would be the case without an enocder) would not. Thus the generator is less likely to suffer mode collapse due the representations learned by the encoder.*\n",
        "\n",
        "\n",
        "\n",
        "### 2. Loss functions (3 points)\n",
        "\n",
        "In the above model that you trained, there are different loss functions for the autoencoder, generator, and discriminator. For each pair of losses, describe whether and how the two losses are in conflict. That is, when training your model, does reducing loss #1 tend to increase loss #2? Why or why not?\n",
        "\n",
        "* a. Generator loss and discriminator loss\n",
        "* b. Generator loss and autoencoder loss\n",
        "* c. Discriminator loss and autoencoder loss\n",
        "\n",
        "\n",
        "a) The generator and the discriminator loss are in conflict - the generator decreases it's loss when it fools the discriminator, and the discriminator's loss decreases when it is not fooled. Reducing the generator's loss means producing more realistic images from hidden spaces, which means that the discriminator will be fooled more often increasing it’s loss. Similarly, as the discriminator reduces it’s loss by classifying the generator’s images as fake, the generator’s loss will increase. \n",
        "\n",
        "\n",
        "b) The generator and autoencoder loss are sometimes in conflict. Both the generator and the autoencoder loss decrease as the generator learns to generate numbers instead of noise. However, the generator may overfit on one of the tasks - for example it can learn to generate images that fool the discriminator, rotating over a few output images at the expense of not being able to reproduce the details of the original image on an autoencoding task. This is related to the concept of mode collapse in the first question. \n",
        "\n",
        "\n",
        "c) The discriminator and autoencoder loss are sometimes in conflict. These losses don’t seem to share share much commonality in the pieces of the architecture they affect. However it is possible that decreasing the autoencoder loss will lead to a higher discriminator loss as the generator component learns to produce better numbers.\n",
        "\n",
        "### 3. Class conditioning (2 points)\n",
        "\n",
        "Suppose you wanted to add in class-conditioning to [the generator and discriminator](https://arxiv.org/pdf/1411.1784.pdf) and [the autoencoder](https://proceedings.neurips.cc/paper/2015/file/8d55a249e6baa5c06772297520da2051-Paper.pdf) in your model. How and why would this change your loss function(s)?\n",
        "\n",
        "*Adding class-conditioning to the generator and discriminator would not change the loss function very much: instead of log(D(x)) and log(1-D(G(z))), we would condition the input x and the latent space z on the class y, getting log(D(x|y) and log(1-D(G(z|y)).*\n",
        "\n",
        "*For class-conditioned autoencoders (like the CVAEs in the paper), the loss function changes in a similar way. We've seen how the loss function for an AE can be represented in log terms. Instead of the log-likelihood, we are now trying to maximize the conditional log-likelihood.*\n"
      ],
      "metadata": {
        "id": "_7SU0EE17qLI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G-EEvPqQR-gX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}